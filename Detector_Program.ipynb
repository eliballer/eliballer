{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNC4Bb322qYG/At9Zfc3E4g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliballer/eliballer/blob/main/Detector_Program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KiBGWTisnGXr"
      },
      "outputs": [],
      "source": [
        "import tensorflow.lite as tflite\n",
        "\n",
        "# Load the model\n",
        "interpreter = tflite.Interpreter(model_path=\"/content/best_float32.tflite\")\n",
        "interpreter.allocate_tensors()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Input Details:\", input_details)\n",
        "print(\"Output Details:\", output_details)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFzLUBWU1ouJ",
        "outputId": "4ad36118-00f3-42f9-92ae-cdc3f465a649"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Details: [{'name': 'images', 'index': 0, 'shape': array([  1, 640, 640,   3], dtype=int32), 'shape_signature': array([  1, 640, 640,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "Output Details: [{'name': 'Identity', 'index': 405, 'shape': array([   1,    9, 8400], dtype=int32), 'shape_signature': array([   1,    9, 8400], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the image\n",
        "input_shape = input_details[0]['shape']  # e.g., [1, 224, 224, 3]\n",
        "image = Image.open(\"/content/Img.jpg\").resize((input_shape[1], input_shape[2]))\n",
        "input_data = np.expand_dims(np.array(image, dtype=np.float32) / 255.0, axis=0)\n",
        "input_data = input_data.astype(input_details[0]['dtype'])\n"
      ],
      "metadata": {
        "id": "xr0No0pj1tyA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get output tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Model Output:\", output_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBuD5L_L6Xjw",
        "outputId": "7868ee6c-2eb3-479f-d043-9e3c03286c3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Output: [[[7.2077401e-03 1.8808380e-02 3.1744108e-02 ... 8.8094109e-01\n",
            "   9.3028915e-01 9.7601056e-01]\n",
            "  [4.1203089e-03 1.5002787e-03 8.3169006e-03 ... 9.6305019e-01\n",
            "   9.6296072e-01 9.7247255e-01]\n",
            "  [1.9348612e-01 1.8510208e-01 1.8138893e-01 ... 7.5345242e-01\n",
            "   7.4589610e-01 7.4643999e-01]\n",
            "  ...\n",
            "  [1.3092502e-04 1.3413782e-04 1.3628369e-04 ... 1.9228287e-03\n",
            "   1.9220319e-03 1.9548861e-03]\n",
            "  [1.3853041e-04 1.4133357e-04 1.4506378e-04 ... 2.4314218e-03\n",
            "   2.4123667e-03 2.4783222e-03]\n",
            "  [1.5984119e-04 1.5285258e-04 1.5222220e-04 ... 1.6503589e-03\n",
            "   1.6451065e-03 1.7301192e-03]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example mapping of class IDs to XAF denominations\n",
        "denomination_mapping = {\n",
        "    0: 500,    # Class ID 0 represents 500 XAF\n",
        "    1: 1000,   # Class ID 1 represents 1000 XAF\n",
        "    2: 2000,   # Class ID 2 represents 2000 XAF\n",
        "    3: 5000,   # Class ID 3 represents 5000 XAF\n",
        "    4: 10000   # Class ID 4 represents 10000 XAF\n",
        "}\n",
        "\n",
        "# Post-process model output\n",
        "output_shape = output_data.shape\n",
        "print(\"Output Shape:\", output_shape)\n",
        "\n",
        "# Flatten the output if it's multidimensional\n",
        "flat_output = np.reshape(output_data, (-1, output_shape[-1]))  # Flatten all except the last dimension\n",
        "\n",
        "# Find the predicted class and confidence for each region\n",
        "total_amount = 0\n",
        "for row in flat_output:\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probabilities = np.exp(row) / np.sum(np.exp(row))\n",
        "\n",
        "    # Find the predicted class and its confidence\n",
        "    predicted_class = np.argmax(probabilities)\n",
        "    confidence = probabilities[predicted_class]\n",
        "\n",
        "    # Add to total amount if confidence is above threshold\n",
        "    if confidence > 0.5:  # Confidence threshold\n",
        "        total_amount += denomination_mapping.get(predicted_class, 0)\n",
        "\n",
        "print(f\"Total Amount Detected: {total_amount} XAF\")"
      ],
      "metadata": {
        "id": "CKwDL8zo6vby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da67ba96-4cce-4d49-a1d2-86d2c1b41edc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Shape: (1, 9, 8400)\n",
            "Total Amount Detected: 0 XAF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example mapping of class IDs to XAF denominations\n",
        "denomination_mapping = {\n",
        "    0: 500,    # Class ID 0 represents 500 XAF\n",
        "    1: 1000,   # Class ID 1 represents 1000 XAF\n",
        "    2: 2000,   # Class ID 2 represents 2000 XAF\n",
        "    3: 5000,   # Class ID 3 represents 5000 XAF\n",
        "    4: 10000   # Class ID 4 represents 10000 XAF\n",
        "}\n",
        "\n",
        "# Post-process model output\n",
        "output_shape = output_data.shape\n",
        "print(\"Output Shape:\", output_shape)\n",
        "\n",
        "# Flatten the output if it's multidimensional\n",
        "flat_output = np.reshape(output_data, (-1, output_shape[-1]))  # Flatten all except the last dimension\n",
        "\n",
        "# Find the predicted class and confidence for each region\n",
        "total_amount = 0\n",
        "for row in flat_output:\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    probabilities = np.exp(row) / np.sum(np.exp(row))\n",
        "\n",
        "    # Find the predicted class and its confidence\n",
        "    predicted_class = np.argmax(probabilities)\n",
        "    confidence = probabilities[predicted_class]\n",
        "\n",
        "    # Add to total amount if confidence is above threshold\n",
        "    if confidence > 0.5:  # Confidence threshold\n",
        "        total_amount += denomination_mapping.get(predicted_class, 0)\n",
        "\n",
        "print(f\"Total Amount Detected: {total_amount} XAF\")"
      ],
      "metadata": {
        "id": "o50Yt4Q1Rpil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}